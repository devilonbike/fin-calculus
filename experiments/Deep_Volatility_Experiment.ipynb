{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep Volatility Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOmwGOcd4Ym6FSs1HHag5+d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/devilonbike/fin-adventure/blob/main/Deep_Volatility_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKGTL16Xu-zp"
      },
      "source": [
        "Copyright 2020 Raghavendra Bazari\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     https://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        "Unless required by applicable law or agreed to in writing, software\n",
        "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "See the License for the specific language governing permissions and\n",
        "limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwzca8jukIEE"
      },
      "source": [
        "# Library Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rIi8wmAm120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fc8bbc3-54c2-4bff-9123-21c0cd35cb4a"
      },
      "source": [
        "!pip install tf_quant_finance\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tf_quant_finance as tff\n",
        "from tf_quant_finance.math import *\n",
        "from tf_quant_finance.math.piecewise import *\n",
        "\n",
        "from tf_quant_finance.models import *\n",
        "from tf_quant_finance.models.generic_ito_process import *\n",
        "from tf_quant_finance.models.generic_ito_process import *\n",
        "\n",
        "import time\n",
        "\n",
        "import scipy.optimize as optimize"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tf_quant_finance in /usr/local/lib/python3.7/dist-packages (0.0.1.dev28)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from tf_quant_finance) (3.17.3)\n",
            "Requirement already satisfied: numpy>=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tf_quant_finance) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability>=0.11.0 in /usr/local/lib/python3.7/dist-packages (from tf_quant_finance) (0.13.0)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.7/dist-packages (from tf_quant_finance) (21.2.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.11.0->tf_quant_finance) (0.1.6)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.11.0->tf_quant_finance) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.11.0->tf_quant_finance) (4.4.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.11.0->tf_quant_finance) (1.15.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability>=0.11.0->tf_quant_finance) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PgMPxJzSWfw0",
        "outputId": "a28269c5-b071-4646-8257-3f8e05d9e67b"
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.6.0'"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9034FqNUehMe"
      },
      "source": [
        "# Model Setup\n",
        "Let's start by defining a *toy model* (generic Ito Process), which will be function of specific model parameters. \n",
        "\n",
        "This model can be used to price call options with specific *maturities* and *strikes* and therefore implied vols (using blackscholes one to one mapping between prie and implied vol).\n",
        "\n",
        "Our aim find the values of model paramters such that implied vols calculated from *this* model matches with implied vols obtained from market (this process is called calibration)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a-_BSMG8jyF0"
      },
      "source": [
        "## Model Definition\n",
        "Creating a toy model definition by following [lognormal](https://en.wikipedia.org/wiki/Log-normal_distributio) fx, [vasicek](https://en.wikipedia.org/wiki/Vasicek_model) ir & [local vol](https://en.wikipedia.org/wiki/Local_volatility) fx_vol"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8RhOyp7p4fT"
      },
      "source": [
        "class TimeSeries:\n",
        "  \"\"\" Container that represent piecewise functions of time, compatible with XLA\"\"\"\n",
        "  def __init__(self,jump_locations, values):\n",
        "    self.jump_locations = jump_locations\n",
        "    self.values = values\n",
        "\n",
        "  def apply(self, input):\n",
        "    res = self.values[-1] \n",
        "    for idx in range(len(self.jump_locations)):\n",
        "      curr_jump_loc = self.jump_locations[idx]\n",
        "      if input <= curr_jump_loc:\n",
        "        res = self.values[idx]\n",
        "    return res\n",
        "\n",
        "class BlackScholesWithVasicelAndLocalVol(GenericItoProcess):\n",
        "  \"\"\"Toy Model for lognormal fx, vasicek ir & local vol fx\"\"\"\n",
        "\n",
        "  def __init__(self,\n",
        "               # rate 1 model paramters\n",
        "               kappa_rate_1, theta_rate_1, vol_rate_1, fwd_rate_1,\n",
        "               # rate 2 model paramters\n",
        "               kappa_rate_2, theta_rate_2, vol_rate_2, fwd_rate_2,\n",
        "               # fx vol model paramters\n",
        "               jump_strikes, local_vol_fx,\n",
        "               # fx model paramters\n",
        "               fx_fwd,\n",
        "               # correlation matrix\n",
        "               corr_matrix,\n",
        "               # descretiozation jump dt\n",
        "               step_size,\n",
        "               # numerical accuracy specifics\n",
        "               dtype=None):\n",
        "    \n",
        "    # basic variables from parent class 'GenericItoProcess' \n",
        "    self._name = 'BlackScholesWithVasicelAndLocalVol'\n",
        "    self._dim = 4\n",
        "    self._dtype = dtype\n",
        "\n",
        "    # rate 1 model paramters\n",
        "    self.kappa_rate_1 = kappa_rate_1;\n",
        "    self.theta_rate_1 = theta_rate_1;\n",
        "    self.vol_rate_1 = vol_rate_1;\n",
        "    self.fwd_rate_1 = fwd_rate_1;\n",
        "\n",
        "    # rate 2 model paramters\n",
        "    self.kappa_rate_2 = kappa_rate_2;\n",
        "    self.theta_rate_2 = theta_rate_2;\n",
        "    self.vol_rate_2 = vol_rate_2;\n",
        "    self.fwd_rate_2 = fwd_rate_2;\n",
        "\n",
        "    # fx vol model paramters\n",
        "    self.jump_strikes = jump_strikes\n",
        "    self.log_jump_strikes = tf.math.log(jump_strikes)\n",
        "    self.local_vol_fx = local_vol_fx;\n",
        "\n",
        "    # fx model paramters\n",
        "    self.fx_fwd = fx_fwd\n",
        "\n",
        "    # descretiozation jump dt\n",
        "    self.step_size = step_size\n",
        "\n",
        "    # correlation matrix\n",
        "    self.cholesky = tf.linalg.cholesky(corr_matrix);   \n",
        "\n",
        "  def _volatility_fn(self, t, x):\n",
        "\n",
        "    vol_fx = x[..., 2]\n",
        "    zeros = tf.zeros_like(vol_fx)\n",
        "    ones = tf.ones_like(vol_fx)\n",
        "\n",
        "    vol_rate_1 = self.vol_rate_1.apply(t) * ones\n",
        "    vol_rate_2 = self.vol_rate_2.apply(t) * ones\n",
        "    vol_vol_fx = zeros\n",
        "\n",
        "    vol_array = [ vol_rate_1, vol_rate_2,vol_vol_fx, vol_fx]\n",
        "    \n",
        "    columns = [];\n",
        "    for col in range(self._dim):\n",
        "      current_columns = []\n",
        "      for row in range(self._dim):\n",
        "        current_columns.append(self.cholesky[row][col] * vol_array[row])\n",
        "      columns.append(tf.stack(current_columns, -1))\n",
        "      \n",
        "    result_matrix = tf.stack(columns, -1)\n",
        "    return result_matrix\n",
        "\n",
        "  def _drift_fn(self, t, x):\n",
        "    rate_factor_1 = x[..., 0]\n",
        "    rate_factor_2 = x[..., 1]\n",
        "    vol_fx = x[..., 2]\n",
        "    log_fx = x[..., 3]\n",
        "    \n",
        "    fwd_rate_1_t = self.fwd_rate_1.apply(t)\n",
        "    fwd_rate_2_t = self.fwd_rate_2.apply(t)\n",
        "\n",
        "    rate_1 = fwd_rate_1_t + rate_factor_1\n",
        "    rate_2 = fwd_rate_2_t + rate_factor_2\n",
        "    \n",
        "    lv_for_current_t = self.local_vol_fx.apply(t)\n",
        "    lv_func = PiecewiseConstantFunc(jump_locations=self.log_jump_strikes, values=lv_for_current_t, dtype=dtype)\n",
        "    new_vol_fx = lv_func(log_fx)\n",
        "    \n",
        "    self.old_vol = new_vol_fx\n",
        "\n",
        "    drift_rate_1 = self.kappa_rate_1.apply(t) * (self.theta_rate_1.apply(t) - rate_factor_1)\n",
        "    drift_rate_2 = self.kappa_rate_2.apply(t) * (self.theta_rate_2.apply(t) - rate_factor_2)\n",
        "    drift_vol_fx = (new_vol_fx - vol_fx)/self.step_size\n",
        "    drift_fx = (rate_1 - rate_2) - 0.5 * vol_fx * vol_fx\n",
        "\n",
        "    drift = tf.stack([ drift_rate_1, drift_rate_2, drift_vol_fx, drift_fx ], -1)\n",
        "    return drift \n",
        "\n",
        "  def implied_vol(self,\n",
        "                  option_strikes,\n",
        "                  option_maturities,\n",
        "                  num_samples):\n",
        "    \n",
        "    paths = self.sample_paths(\n",
        "          option_maturities,\n",
        "          num_samples=num_samples,\n",
        "          initial_state=np.array([0.0, 0.0, 0.0, 0.0], dtype=self._dtype.name),\n",
        "          time_step=self.step_size,\n",
        "          random_type=tff.math.random.RandomType.STATELESS_ANTITHETIC,\n",
        "          seed=[42, 56])\n",
        "\n",
        "    number_of_strikes = len(option_strikes)\n",
        "    implied_vols = []\n",
        "    for maturity_idx in range(len(option_maturities)):\n",
        "      curr_maturity = option_maturities[maturity_idx]\n",
        "      curr_paths = paths[:,maturity_idx]\n",
        "      curr_fwd = self.fx_fwd.apply(curr_maturity)\n",
        "      df = tf.exp(-curr_paths[:,0]*curr_maturity)\n",
        "      df_mean = tf.math.reduce_mean(df) \n",
        "      fx = curr_fwd * tf.exp(curr_paths[:,3])\n",
        "      \n",
        "      prices = []\n",
        "      for strike_idx in range(number_of_strikes):\n",
        "        curr_strike = option_strikes[strike_idx]\n",
        "        price = tf.math.reduce_mean(tf.maximum(tf.constant(0.0, dtype=self._dtype), (fx - curr_strike)))\n",
        "        prices.append(price)\n",
        "  \n",
        "      implied_vols_for_curr_expiry = tff.black_scholes.implied_vol(\n",
        "          prices=prices,\n",
        "          strikes=option_strikes,\n",
        "          expiries= [curr_maturity] * number_of_strikes,\n",
        "          forwards=[curr_fwd] * number_of_strikes,\n",
        "          discount_factors= [df_mean] * number_of_strikes,\n",
        "          is_call_options=True)\n",
        "    \n",
        "      implied_vols_for_curr_expiry_parsed = []\n",
        "      for option_idx in range(0, len(implied_vols_for_curr_expiry)):\n",
        "        curr_implied_vol = implied_vols_for_curr_expiry[option_idx] \n",
        "        if np.isnan(curr_implied_vol):\n",
        "          curr_implied_vol = min(0, prices[option_idx].numpy() - max(curr_fwd - option_strikes[option_idx], 0))\n",
        "        implied_vols_for_curr_expiry_parsed.append(curr_implied_vol)\n",
        "  \n",
        "      implied_vols.append(implied_vols_for_curr_expiry_parsed)\n",
        "\n",
        "    return implied_vols"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4czd6d_QkVHh"
      },
      "source": [
        "## Model Initialization\n",
        "\n",
        "Initialize the model with dummy values of model parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_HNxU8FkZxN"
      },
      "source": [
        "# Let's instantiate a model with dummy model paramter values\n",
        "\n",
        "dtype=tf.float64\n",
        "jump_locations = np.array([0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.7, 0.9, 1.1])\n",
        "jump_strikes = np.array([0.95, 0.99 , 1, 1.001])\n",
        "\n",
        "# This is one of the model paramters, that we are going to keep changing\n",
        "lv_surface = [[0.6, 0.36, 0.246, 0.546, 0.7978],\n",
        "              [0.68, 0.37, 0.112, 0.476, 0.8987],\n",
        "              [0.65, 0.33, 0.224, 0.676, 0.764],\n",
        "              [0.634, 0.336, 0.332, 0.566, 0.907],\n",
        "              [0.76, 0.456, 0.152, 0.601, 0.67],\n",
        "              [0.676, 0.3745, 0.1632, 0.623, 0.788],\n",
        "              [0.687, 0.243, 0.2123, 0.622, 0.7576],\n",
        "              [0.576, 0.473, 0.253, 0.556, 0.7123],\n",
        "              [0.56, 0.346, 0.2252, 0.786, 0.867],\n",
        "              [0.786, 0.354, 0.2691, 0.634, 0.7545]]\n",
        "\n",
        "model = BlackScholesWithVasicelAndLocalVol(\n",
        "    kappa_rate_1 = TimeSeries(jump_locations=jump_locations, values=np.array([0.05, 0.02, 0.07, 0.02, 0.04, 0.06, 0.07, 0.02, 0.08, 0.09],dtype=dtype.name)),\n",
        "    theta_rate_1 = TimeSeries(jump_locations=jump_locations, values=np.array([1.2, 2, 1.5, 1.7, 1, 1.3, 1.9, 3.0, 2.5, 1.0],dtype=dtype.name)),\n",
        "    vol_rate_1 = TimeSeries(jump_locations=jump_locations, values=np.array([0.11, 0.15, 0.9, 0.15,  0.15, 0.3, 0.15, 0.2, 0.17, 0.4],dtype=dtype.name)),\n",
        "    fwd_rate_1 = TimeSeries(jump_locations=jump_locations, values=np.array([0.02, 0.021, 0.022, 0.023, 0.019, 0.018, 0.23, 0.025, 0.015, 0.019],dtype=dtype.name)),\n",
        "    kappa_rate_2 = TimeSeries(jump_locations=jump_locations, values=np.array([0.05, 0.02, 0.07, 0.02, 0.04, 0.06, 0.07, 0.02, 0.08, 0.09],dtype=dtype.name)),\n",
        "    theta_rate_2 = TimeSeries(jump_locations=jump_locations, values=np.array([1.2, 2, 1.5, 1.7, 1, 1.3, 1.9, 3.0, 2.5, 1.0],dtype=dtype.name)),\n",
        "    vol_rate_2 = TimeSeries(jump_locations=jump_locations, values=np.array([0.11, 0.15, 0.9, 0.15,  0.15, 0.3, 0.15, 0.2, 0.17, 0.4],dtype=dtype.name)),\n",
        "    fwd_rate_2 = TimeSeries(jump_locations=jump_locations, values=np.array([0.025, 0.051, 0.052, 0.053, 0.069, 0.068, 0.53, 0.055, 0.075, 0.049],dtype=dtype.name)),\n",
        "    jump_strikes = jump_strikes,\n",
        "    fx_fwd = TimeSeries(jump_locations=jump_locations, values=np.array([1.0, 1.002, 0.998, 1.04, 1.035, 1.01, 0.999, 0.998, 1.003, 1.01],dtype=dtype.name)),\n",
        "    local_vol_fx = TimeSeries(jump_locations=jump_locations, values=lv_surface),\n",
        "    step_size=0.01,\n",
        "    corr_matrix = tf.constant([[1.0, 0.2, 0.0, 0.3],\n",
        "                               [0.2, 1.0, 0.0, 0.3],\n",
        "                               [0.0, 0.0, 1.0, 0.8],\n",
        "                               [0.3, 0.3, 0.8, 1.0]], dtype=dtype),\n",
        "    dtype=dtype\n",
        ")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y7zf2JZ-k--g"
      },
      "source": [
        "## Model Calibration\n",
        "\n",
        "To keep things simple let's just try to find the *lv_surface* that will map closest match to our target i.e implied_vol from market.\n",
        "\n",
        "Moment of truth: Given the input dimenion of objective function is 50 ('local_vol_fx' surface of size 10x5 i.e 10 maturities by 5 strikes) and similarly output dimension is 50 as well, below cell execution will take forever. (if one really wants to test the execution, can reduce *option_maturities* to size of 1 array)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BDIBRUNm8T4",
        "outputId": "5f0f7d06-e98f-4a16-d4f9-b68386be8d05"
      },
      "source": [
        "# These are alll the maturities we want to reprice our call options\n",
        "option_maturities = [0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
        "option_maturities = [ 0.05 ] # <-- uncomment this if interested in watching execution finish in few mins\n",
        "number_of_maturities = len(option_maturities)\n",
        "\n",
        "# These are alll the strikes (on each of above 'option_maturities') of those call options\n",
        "option_strikes =np.array([0.95, 0.99 , 1, 1.001, 1.05])\n",
        "number_of_strikes = len(option_strikes)\n",
        "\n",
        "# Number of Monte carlo paths\n",
        "num_samples = 40000\n",
        "\n",
        "# Let's say this is the implied vol coming from market\n",
        "implied_vol_target = np.array([ [ 0.36165047, 0.38006929, 0.38622322, 0.38688029, 0.42223257 ],\n",
        "       [ 0.49930734, 0.52086326, 0.52665937, 0.52725076, 0.5561736 ],\n",
        "       [ 0.53926329, 0.56007775, 0.56558462, 0.56613531, 0.59324591 ],\n",
        "       [ 0.55870456, 0.57847004, 0.5836174 , 0.58413716, 0.60937169 ],\n",
        "       [ 0.58499617, 0.60206912, 0.60646861, 0.60690938, 0.62796077 ],\n",
        "       [ 0.61917847, 0.63211846, 0.63541694, 0.63574893, 0.65183933 ],\n",
        "       [ 0.64890557, 0.65896691, 0.66159441, 0.66185734, 0.67469815 ],\n",
        "       [ 0.68506316, 0.69196701, 0.69382324, 0.69401138, 0.70335816 ],\n",
        "       [ 0.74270218, 0.74599681, 0.74702723, 0.74713323, 0.75264819 ],\n",
        "       [ 0.8005369 , 0.79634181, 0.79554414, 0.79546886, 0.7927459 ] ])\n",
        "\n",
        "\n",
        "implied_vol_target = implied_vol_target[:number_of_maturities] # slice till 'number_of_maturities', just in case user wants to try reduced number of maturities\n",
        "\n",
        "# This is the initial guess for our LV surface (one of the model parameters of model)\n",
        "lv_surface_init_guess = np.array([[0.6, 0.36, 0.246, 0.546, 0.7978],\n",
        "                         [0.68, 0.37, 0.112, 0.476, 0.8987],\n",
        "                         [0.65, 0.33, 0.224, 0.676, 0.764],\n",
        "                         [0.634, 0.336, 0.332, 0.566, 0.907],\n",
        "                         [0.76, 0.456, 0.152, 0.601, 0.67],\n",
        "                         [0.676, 0.3745, 0.1632, 0.623, 0.788],\n",
        "                         [0.687, 0.243, 0.2123, 0.622, 0.7576],\n",
        "                         [0.576, 0.473, 0.253, 0.556, 0.7123],\n",
        "                         [0.56, 0.346, 0.2252, 0.786, 0.867],\n",
        "                         [0.786, 0.354, 0.2691, 0.634, 0.7545]])\n",
        "                       \n",
        "lv_surface_init_guess = lv_surface_init_guess[:number_of_maturities] # slice till 'number_of_maturities', just in case user wants to try reduced number of maturities\n",
        "\n",
        "# Let's define our objective function\n",
        "def objective_fn(lv_surface_guess_flatened):\n",
        "  lv_surface_guess = np.split(lv_surface_guess_flatened, number_of_maturities)\n",
        "  model.local_vol_fx = TimeSeries(jump_locations=option_maturities[:-1], values=lv_surface_guess)\n",
        "  implied_vols_from_model = model.implied_vol(option_maturities=option_maturities, option_strikes=option_strikes,num_samples=num_samples)\n",
        "  errors = np.array((implied_vol_target - implied_vols_from_model)).flatten() * 1e4 # in bps\n",
        "  # print(\"errors:\", errors)\n",
        "  return errors\n",
        "\n",
        "# Feel free to use your favourite optimizer\n",
        "roots = optimize.least_squares(objective_fn,\n",
        "                      x0= lv_surface_init_guess.flatten(), \n",
        "                      ftol=0.05,\n",
        "                      xtol=None,\n",
        "                      gtol=None,)\n",
        "\n",
        "roots.x # this is best lv_surface that should be used in model, as it closely maps to implied_vols_from_model to 'implied_vol_target'\n",
        "\n",
        "#  roots.x should be \n",
        "#\n",
        "# [ [0.786, 0.354, 0.2691, 0.634, 0.07545],\n",
        "#   [0.812, 0.377, 0.112, 0.476, 0.987 ],\n",
        "#   [0.687, 0.243, 0.2123, 0.622, 0.7576],\n",
        "#   [0.65, 0.33, 0.224, 0.676, 0.764],\n",
        "#   [0.576, 0.473, 0.0253, 0.556, 0.7123],\n",
        "#   [0.634, 0.36, 0.0332, 0.566, 0.907],\n",
        "#   [0.76, 0.456, 0.0152, 0.601, 0.67],\n",
        "#   [0.676, 0.03745, 0.1632, 0.623, 0.7088],\n",
        "#   [0.56, 0.346, 0.2252, 0.0786, 0.867],\n",
        "#   [0.786, 0.354, 0.2691, 0.634, 0.7545] ]\n",
        "#\n",
        "# for above 'implied_vol_target' values\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.68788556, 0.31760474, 0.21749341, 1.40714695, 0.84382973])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTX44lflr8_S"
      },
      "source": [
        "# Using Machine learning to reduce calibration time\n",
        "\n",
        "Now we should try to reduce calibration time complexity using machine learning. The major bottleneck in above calibration is repeated calls to *model.implied_vol* function inside optimizer which is quite heavy due to Monte-Carlo Simulation.\n",
        "\n",
        "If somehow we can learn that function (which is mapping local_vol model parameter to implied vol), then we can use that function underneath the optimizer as replacement and it would be many fold faster!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-7O21QRfYGY"
      },
      "source": [
        "## Training Data Generation\n",
        "First step is generate training dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQ5D2Ob_Guft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c496ba-4bb2-40cf-8962-6dd0b217802f"
      },
      "source": [
        "# These are alll the maturities we want to reprice our call options\n",
        "option_maturities = [0.05, 0.1, 0.15, 0.2, 0.3, 0.5, 0.7, 0.9, 1.1, 1.3]\n",
        "number_of_maturities = len(option_maturities)\n",
        "\n",
        "# Let's say this is the implied vol coming from market\n",
        "implied_vol_target = np.array([ [ 0.36165047, 0.38006929, 0.38622322, 0.38688029, 0.42223257 ],\n",
        "       [ 0.49930734, 0.52086326, 0.52665937, 0.52725076, 0.5561736 ],\n",
        "       [ 0.53926329, 0.56007775, 0.56558462, 0.56613531, 0.59324591 ],\n",
        "       [ 0.55870456, 0.57847004, 0.5836174 , 0.58413716, 0.60937169 ],\n",
        "       [ 0.58499617, 0.60206912, 0.60646861, 0.60690938, 0.62796077 ],\n",
        "       [ 0.61917847, 0.63211846, 0.63541694, 0.63574893, 0.65183933 ],\n",
        "       [ 0.64890557, 0.65896691, 0.66159441, 0.66185734, 0.67469815 ],\n",
        "       [ 0.68506316, 0.69196701, 0.69382324, 0.69401138, 0.70335816 ],\n",
        "       [ 0.74270218, 0.74599681, 0.74702723, 0.74713323, 0.75264819 ],\n",
        "       [ 0.8005369 , 0.79634181, 0.79554414, 0.79546886, 0.7927459 ] ])\n",
        "\n",
        "\n",
        "implied_vol_target = implied_vol_target[:number_of_maturities] # slice till 'number_of_maturities', just in case user wants to try reduced number of maturities\n",
        "\n",
        "# These are alll the strikes (on each of above 'option_maturities') of those call options\n",
        "option_strikes =np.array([0.95, 0.99 , 1, 1.001, 1.05])\n",
        "number_of_strikes = len(option_strikes)\n",
        "\n",
        "# Number of Monte carlo paths\n",
        "num_samples = 40000\n",
        "\n",
        "training_samples = 2 # Warning!! takes fair amount of time, feel free to change as per requirement (can use GPUs to speedup)\n",
        "np.random.seed(0)\n",
        "\n",
        "features = []\n",
        "number_of_features = number_of_maturities * number_of_strikes\n",
        "for i in range(number_of_features):\n",
        "  features.append(np.random.uniform(0.0, 1.0, training_samples) * 0.0)\n",
        "features = np.array(features).transpose()\n",
        "print(\"features\", features.shape)\n",
        "\n",
        "# plugging each of those surface, we will generate implied vols from that model\n",
        "labels = []\n",
        "for feature in features:\n",
        "  lv_surface = np.split(feature, number_of_maturities)\n",
        "  model.local_vol_fx = TimeSeries(jump_locations=option_maturities[:-1], values=lv_surface)\n",
        "  implied_vols_from_model = model.implied_vol(option_maturities=option_maturities, option_strikes=option_strikes,num_samples=num_samples)\n",
        "  error = (implied_vol_target - implied_vols_from_model) * 1e4\n",
        "  labels.append(np.array(error).flatten())\n",
        "labels = np.array(labels)\n",
        "print(\"labels\", labels.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features (2, 50)\n",
            "labels (2, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KyEmpr47UZ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9d831fb-035e-44c6-e0e1-a6411e24e5f3"
      },
      "source": [
        "features"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HlpdMTw5qpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dce29f7-2ecd-49ca-ca0a-528a89e010c9"
      },
      "source": [
        "labels"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3646.54266289, 3830.73086289, 3887.54963605, 3887.51109308,\n",
              "        4222.3257    , 5053.00674901, 5268.19216027, 5292.36113158,\n",
              "        5289.96413805, 5561.736     , 5482.26246209, 5678.73157323,\n",
              "        5678.54383518, 5675.77342468, 5932.4591    , 5706.11456887,\n",
              "        5866.71059941, 5854.14484552, 5851.21309276, 6093.7169    ,\n",
              "        6024.42910169, 6093.83743897, 6068.69556018, 6016.11012547,\n",
              "        6007.99622977, 6408.63717922, 6350.89564736, 6151.15428095,\n",
              "        6143.89905919, 6102.02368983, 6672.17647335, 6277.01125902,\n",
              "        6221.76149872, 6218.0751216 , 6175.05351345, 6961.06245471,\n",
              "        6338.33266623, 6312.12130565, 6310.03993306, 6273.7324691 ,\n",
              "        6680.06874585, 6574.28323073, 6561.31063487, 6560.19757255,\n",
              "        6533.00343526, 6773.17012834, 6698.96081044, 6683.60927743,\n",
              "        6682.12746094, 6623.78592155],\n",
              "       [3646.54266289, 3830.73086289, 3887.54963605, 3887.51109308,\n",
              "        4222.3257    , 5053.00674901, 5268.19216027, 5292.36113158,\n",
              "        5289.96413805, 5561.736     , 5482.26246209, 5678.73157323,\n",
              "        5678.54383518, 5675.77342468, 5932.4591    , 5706.11456887,\n",
              "        5866.71059941, 5854.14484552, 5851.21309276, 6093.7169    ,\n",
              "        6024.42910169, 6093.83743897, 6068.69556018, 6016.11012547,\n",
              "        6007.99622977, 6408.63717922, 6350.89564736, 6151.15428095,\n",
              "        6143.89905919, 6102.02368983, 6672.17647335, 6277.01125902,\n",
              "        6221.76149872, 6218.0751216 , 6175.05351345, 6961.06245471,\n",
              "        6338.33266623, 6312.12130565, 6310.03993306, 6273.7324691 ,\n",
              "        6680.06874585, 6574.28323073, 6561.31063487, 6560.19757255,\n",
              "        6533.00343526, 6773.17012834, 6698.96081044, 6683.60927743,\n",
              "        6682.12746094, 6623.78592155]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yehk-phqmQFt"
      },
      "source": [
        "## Training\n",
        "Use your favourite API to learn above mapping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "758JgNjNih80"
      },
      "source": [
        "# your code please\n",
        "\n",
        "\n",
        "# after taining, we should have predition function that takes lv_surface and predicts implied vols\n",
        "def prediction_function(lv_surface):\n",
        "  pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9dBpGyntLlA"
      },
      "source": [
        "Now use your prediction function in above calibration step instead of original function and see if you can achieve.\n",
        "1. same accuracy as original function.\n",
        "2. speed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGMbc97qWSRZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiY0nyv6WTGg",
        "outputId": "cfe3c932-6770-4b7a-e14b-e99a73e342ab"
      },
      "source": [
        "!pip install tf_quant_finance\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tf_quant_finance as tff\n",
        "from tf_quant_finance.math import *\n",
        "from tf_quant_finance.math.piecewise import *\n",
        "\n",
        "from tf_quant_finance.models import *\n",
        "from tf_quant_finance.models.generic_ito_process import *\n",
        "from tf_quant_finance.models.generic_ito_process import *\n",
        "\n",
        "import time\n",
        "\n",
        "import scipy.optimize as optimize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tf_quant_finance\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2e/36/d58e404336ab63174f22494d3eb1c1a192d551b96b8a0fcfdef4f735bf59/tf_quant_finance-0.0.1.dev24-py2.py3-none-any.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from tf_quant_finance) (3.12.4)\n",
            "Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.6/dist-packages (from tf_quant_finance) (20.3.0)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf_quant_finance) (1.19.5)\n",
            "Requirement already satisfied: tensorflow-probability>=0.9.0 in /usr/local/lib/python3.6/dist-packages (from tf_quant_finance) (0.12.1)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->tf_quant_finance) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->tf_quant_finance) (51.1.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf_quant_finance) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf_quant_finance) (1.3.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf_quant_finance) (0.1.5)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-probability>=0.9.0->tf_quant_finance) (0.3.3)\n",
            "Installing collected packages: tf-quant-finance\n",
            "Successfully installed tf-quant-finance-0.0.1.dev24\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
